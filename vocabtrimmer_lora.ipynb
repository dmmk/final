{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a53ca71a2cba495eaef75f07e551c001": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ddfabef059364a2cad09a6bc159041e8",
              "IPY_MODEL_00123b70fba44464a12e3f344d252c33",
              "IPY_MODEL_0983b01626ec4f50963588432857fa7b"
            ],
            "layout": "IPY_MODEL_355fdd56096a4b7e8ccac7fffccc620e"
          }
        },
        "ddfabef059364a2cad09a6bc159041e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a28c9c9dbc140a2bb8f85118e5d53cb",
            "placeholder": "​",
            "style": "IPY_MODEL_85c926123c254d25aac3075efc3bdc70",
            "value": "Map: 100%"
          }
        },
        "00123b70fba44464a12e3f344d252c33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6472ffd6c1040bcae27435c50e13ba5",
            "max": 2937,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_50e24eaac0374ceb825aa4a3d8f3baef",
            "value": 2937
          }
        },
        "0983b01626ec4f50963588432857fa7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad7f3353b1fd4d77a2baccd2639bfee6",
            "placeholder": "​",
            "style": "IPY_MODEL_c987b171340f44f4bcb595d95fe31a42",
            "value": " 2937/2937 [00:02&lt;00:00, 1055.35 examples/s]"
          }
        },
        "355fdd56096a4b7e8ccac7fffccc620e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a28c9c9dbc140a2bb8f85118e5d53cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85c926123c254d25aac3075efc3bdc70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6472ffd6c1040bcae27435c50e13ba5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50e24eaac0374ceb825aa4a3d8f3baef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ad7f3353b1fd4d77a2baccd2639bfee6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c987b171340f44f4bcb595d95fe31a42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a53ca71a2cba495eaef75f07e551c001",
            "ddfabef059364a2cad09a6bc159041e8",
            "00123b70fba44464a12e3f344d252c33",
            "0983b01626ec4f50963588432857fa7b",
            "355fdd56096a4b7e8ccac7fffccc620e",
            "3a28c9c9dbc140a2bb8f85118e5d53cb",
            "85c926123c254d25aac3075efc3bdc70",
            "a6472ffd6c1040bcae27435c50e13ba5",
            "50e24eaac0374ceb825aa4a3d8f3baef",
            "ad7f3353b1fd4d77a2baccd2639bfee6",
            "c987b171340f44f4bcb595d95fe31a42"
          ]
        },
        "id": "F4cApJ4XMNDF",
        "outputId": "e2926354-e6f9-4fcc-eb9e-e12c4793c649"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive mounted successfully!\n",
            "Attempting to load trimmed model and tokenizer from: /content/drive/MyDrive/amharic_summarizer_mt5_trimmed_vocabtrimmer\n",
            "Training outputs (checkpoints, logs, results) will be saved to: /content/drive/MyDrive/amharic_summarizer_lora\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.15.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.11/dist-packages (0.1.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: rawpy in /usr/local/lib/python3.11/dist-packages (0.25.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft) (4.52.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft) (4.67.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft) (0.5.3)\n",
            "Requirement already satisfied: huggingface_hub>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from peft) (0.31.2)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.8)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (5.29.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (75.2.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.4.26)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (0.21.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.0)\n",
            "Transformers version: 4.52.1\n",
            "\n",
            "Loading trimmed model from /content/drive/MyDrive/amharic_summarizer_mt5_trimmed_vocabtrimmer...\n",
            "Loading trimmed tokenizer from /content/drive/MyDrive/amharic_summarizer_mt5_trimmed_vocabtrimmer...\n",
            "Trimmed model and tokenizer loaded successfully!\n",
            "Loaded model vocabulary size: 2766\n",
            "Loaded tokenizer vocabulary size: 2866\n",
            "Model moved to device: cuda\n",
            "\n",
            "Dataset loaded from CSV files.\n",
            "Dataset sizes:\n",
            "Train size: 23492\n",
            "Validation size: 2937\n",
            "Test size: 2937\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2937 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a53ca71a2cba495eaef75f07e551c001"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trainable parameters (LoRA on Trimmed Model):\n",
            "trainable params: 344,064 || all params: 47,238,528 || trainable%: 0.7284\n",
            "Training outputs (checkpoints, logs) will be saved to: /content/drive/MyDrive/amharic_summarizer_lora/trimmed_lora_checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-a045e32cfc28>:378: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting training (LoRA on Trimmed Model)...\n",
            "No checkpoint found, starting fresh training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/data/data_collator.py:741: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
            "  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.int64)\n",
            "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5939' max='17619' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 5939/17619 1:30:10 < 2:57:23, 1.10 it/s, Epoch 1.01/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Bleu</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>16.869300</td>\n",
              "      <td>9.504004</td>\n",
              "      <td>0.002713</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002802</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>15.458300</td>\n",
              "      <td>7.460530</td>\n",
              "      <td>0.004965</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004971</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>13.215900</td>\n",
              "      <td>6.123291</td>\n",
              "      <td>0.004994</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004875</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>11.310700</td>\n",
              "      <td>5.097733</td>\n",
              "      <td>0.006583</td>\n",
              "      <td>0.000681</td>\n",
              "      <td>0.006518</td>\n",
              "      <td>0.001126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>9.790400</td>\n",
              "      <td>4.208498</td>\n",
              "      <td>0.006412</td>\n",
              "      <td>0.000681</td>\n",
              "      <td>0.006231</td>\n",
              "      <td>0.000808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>8.411300</td>\n",
              "      <td>3.427741</td>\n",
              "      <td>0.007627</td>\n",
              "      <td>0.000908</td>\n",
              "      <td>0.007513</td>\n",
              "      <td>0.003067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>7.289500</td>\n",
              "      <td>2.891563</td>\n",
              "      <td>0.010095</td>\n",
              "      <td>0.001248</td>\n",
              "      <td>0.010124</td>\n",
              "      <td>0.016303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>6.338500</td>\n",
              "      <td>2.656048</td>\n",
              "      <td>0.011615</td>\n",
              "      <td>0.001612</td>\n",
              "      <td>0.011773</td>\n",
              "      <td>0.033917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>5.724300</td>\n",
              "      <td>2.493115</td>\n",
              "      <td>0.014879</td>\n",
              "      <td>0.002009</td>\n",
              "      <td>0.014967</td>\n",
              "      <td>0.047722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>5.211000</td>\n",
              "      <td>2.356737</td>\n",
              "      <td>0.022393</td>\n",
              "      <td>0.002469</td>\n",
              "      <td>0.022501</td>\n",
              "      <td>0.059529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>4.914100</td>\n",
              "      <td>2.252124</td>\n",
              "      <td>0.026736</td>\n",
              "      <td>0.003240</td>\n",
              "      <td>0.026934</td>\n",
              "      <td>0.076242</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CUDA cache cleared and gc.collect() called by callback before evaluation at step 500.\n",
            "\n",
            "--- Inside compute_metrics (DEBUG) ---\n",
            "Type of eval_pred.predictions (initial): <class 'tuple'>\n",
            "Type of eval_pred.label_ids (initial): <class 'numpy.ndarray'>\n",
            "eval_pred.predictions is a tuple. Length: 2\n",
            "Taking first element of predictions tuple. New type: <class 'numpy.ndarray'>\n",
            "Predictions type (after initial processing): <class 'numpy.ndarray'>\n",
            "Labels type (after initial processing): <class 'numpy.ndarray'>\n",
            "WARNING: Predictions has unexpected 3 dimensions. Assuming logits and applying argmax.\n",
            "Predictions after argmax: New shape: (2937, 107), New dtype: int64\n",
            "Predictions shape (after processing): (2937, 107)\n",
            "Labels shape (after processing): (2937, 107)\n",
            "Labels processed (replaced -100).\n",
            "Successfully decoded 2937 predictions and 2937 labels.\n",
            "Empty strings in decoded predictions/labels replaced with 'a' for robust metric calculation.\n",
            "Labels formatted for metrics.\n",
            "ROUGE computed.\n",
            "BLEU computed.\n",
            "Metrics combined.\n",
            "--- Exiting compute_metrics ---\n",
            "\n",
            "CUDA cache cleared and gc.collect() called by callback before evaluation at step 1000.\n",
            "\n",
            "--- Inside compute_metrics (DEBUG) ---\n",
            "Type of eval_pred.predictions (initial): <class 'tuple'>\n",
            "Type of eval_pred.label_ids (initial): <class 'numpy.ndarray'>\n",
            "eval_pred.predictions is a tuple. Length: 2\n",
            "Taking first element of predictions tuple. New type: <class 'numpy.ndarray'>\n",
            "Predictions type (after initial processing): <class 'numpy.ndarray'>\n",
            "Labels type (after initial processing): <class 'numpy.ndarray'>\n",
            "WARNING: Predictions has unexpected 3 dimensions. Assuming logits and applying argmax.\n",
            "Predictions after argmax: New shape: (2937, 107), New dtype: int64\n",
            "Predictions shape (after processing): (2937, 107)\n",
            "Labels shape (after processing): (2937, 107)\n",
            "Labels processed (replaced -100).\n",
            "Successfully decoded 2937 predictions and 2937 labels.\n",
            "Empty strings in decoded predictions/labels replaced with 'a' for robust metric calculation.\n",
            "Labels formatted for metrics.\n",
            "ROUGE computed.\n",
            "BLEU computed.\n",
            "Metrics combined.\n",
            "--- Exiting compute_metrics ---\n",
            "\n",
            "CUDA cache cleared and gc.collect() called by callback before evaluation at step 1500.\n",
            "\n",
            "--- Inside compute_metrics (DEBUG) ---\n",
            "Type of eval_pred.predictions (initial): <class 'tuple'>\n",
            "Type of eval_pred.label_ids (initial): <class 'numpy.ndarray'>\n",
            "eval_pred.predictions is a tuple. Length: 2\n",
            "Taking first element of predictions tuple. New type: <class 'numpy.ndarray'>\n",
            "Predictions type (after initial processing): <class 'numpy.ndarray'>\n",
            "Labels type (after initial processing): <class 'numpy.ndarray'>\n",
            "WARNING: Predictions has unexpected 3 dimensions. Assuming logits and applying argmax.\n",
            "Predictions after argmax: New shape: (2937, 107), New dtype: int64\n",
            "Predictions shape (after processing): (2937, 107)\n",
            "Labels shape (after processing): (2937, 107)\n",
            "Labels processed (replaced -100).\n",
            "Successfully decoded 2937 predictions and 2937 labels.\n",
            "Empty strings in decoded predictions/labels replaced with 'a' for robust metric calculation.\n",
            "Labels formatted for metrics.\n",
            "ROUGE computed.\n",
            "BLEU computed.\n",
            "Metrics combined.\n",
            "--- Exiting compute_metrics ---\n",
            "\n",
            "CUDA cache cleared and gc.collect() called by callback before evaluation at step 2000.\n",
            "\n",
            "--- Inside compute_metrics (DEBUG) ---\n",
            "Type of eval_pred.predictions (initial): <class 'tuple'>\n",
            "Type of eval_pred.label_ids (initial): <class 'numpy.ndarray'>\n",
            "eval_pred.predictions is a tuple. Length: 2\n",
            "Taking first element of predictions tuple. New type: <class 'numpy.ndarray'>\n",
            "Predictions type (after initial processing): <class 'numpy.ndarray'>\n",
            "Labels type (after initial processing): <class 'numpy.ndarray'>\n",
            "WARNING: Predictions has unexpected 3 dimensions. Assuming logits and applying argmax.\n",
            "Predictions after argmax: New shape: (2937, 107), New dtype: int64\n",
            "Predictions shape (after processing): (2937, 107)\n",
            "Labels shape (after processing): (2937, 107)\n",
            "Labels processed (replaced -100).\n",
            "Successfully decoded 2937 predictions and 2937 labels.\n",
            "Empty strings in decoded predictions/labels replaced with 'a' for robust metric calculation.\n",
            "Labels formatted for metrics.\n",
            "ROUGE computed.\n",
            "BLEU computed.\n",
            "Metrics combined.\n",
            "--- Exiting compute_metrics ---\n",
            "\n",
            "CUDA cache cleared and gc.collect() called by callback before evaluation at step 2500.\n",
            "\n",
            "--- Inside compute_metrics (DEBUG) ---\n",
            "Type of eval_pred.predictions (initial): <class 'tuple'>\n",
            "Type of eval_pred.label_ids (initial): <class 'numpy.ndarray'>\n",
            "eval_pred.predictions is a tuple. Length: 2\n",
            "Taking first element of predictions tuple. New type: <class 'numpy.ndarray'>\n",
            "Predictions type (after initial processing): <class 'numpy.ndarray'>\n",
            "Labels type (after initial processing): <class 'numpy.ndarray'>\n",
            "WARNING: Predictions has unexpected 3 dimensions. Assuming logits and applying argmax.\n",
            "Predictions after argmax: New shape: (2937, 107), New dtype: int64\n",
            "Predictions shape (after processing): (2937, 107)\n",
            "Labels shape (after processing): (2937, 107)\n",
            "Labels processed (replaced -100).\n",
            "Successfully decoded 2937 predictions and 2937 labels.\n",
            "Empty strings in decoded predictions/labels replaced with 'a' for robust metric calculation.\n",
            "Labels formatted for metrics.\n",
            "ROUGE computed.\n",
            "BLEU computed.\n",
            "Metrics combined.\n",
            "--- Exiting compute_metrics ---\n",
            "\n",
            "CUDA cache cleared and gc.collect() called by callback before evaluation at step 3000.\n",
            "\n",
            "--- Inside compute_metrics (DEBUG) ---\n",
            "Type of eval_pred.predictions (initial): <class 'tuple'>\n",
            "Type of eval_pred.label_ids (initial): <class 'numpy.ndarray'>\n",
            "eval_pred.predictions is a tuple. Length: 2\n",
            "Taking first element of predictions tuple. New type: <class 'numpy.ndarray'>\n",
            "Predictions type (after initial processing): <class 'numpy.ndarray'>\n",
            "Labels type (after initial processing): <class 'numpy.ndarray'>\n",
            "WARNING: Predictions has unexpected 3 dimensions. Assuming logits and applying argmax.\n",
            "Predictions after argmax: New shape: (2937, 107), New dtype: int64\n",
            "Predictions shape (after processing): (2937, 107)\n",
            "Labels shape (after processing): (2937, 107)\n",
            "Labels processed (replaced -100).\n",
            "Successfully decoded 2937 predictions and 2937 labels.\n",
            "Empty strings in decoded predictions/labels replaced with 'a' for robust metric calculation.\n",
            "Labels formatted for metrics.\n",
            "ROUGE computed.\n",
            "BLEU computed.\n",
            "Metrics combined.\n",
            "--- Exiting compute_metrics ---\n",
            "\n",
            "CUDA cache cleared and gc.collect() called by callback before evaluation at step 3500.\n",
            "\n",
            "--- Inside compute_metrics (DEBUG) ---\n",
            "Type of eval_pred.predictions (initial): <class 'tuple'>\n",
            "Type of eval_pred.label_ids (initial): <class 'numpy.ndarray'>\n",
            "eval_pred.predictions is a tuple. Length: 2\n",
            "Taking first element of predictions tuple. New type: <class 'numpy.ndarray'>\n",
            "Predictions type (after initial processing): <class 'numpy.ndarray'>\n",
            "Labels type (after initial processing): <class 'numpy.ndarray'>\n",
            "WARNING: Predictions has unexpected 3 dimensions. Assuming logits and applying argmax.\n",
            "Predictions after argmax: New shape: (2937, 107), New dtype: int64\n",
            "Predictions shape (after processing): (2937, 107)\n",
            "Labels shape (after processing): (2937, 107)\n",
            "Labels processed (replaced -100).\n",
            "Successfully decoded 2937 predictions and 2937 labels.\n",
            "Empty strings in decoded predictions/labels replaced with 'a' for robust metric calculation.\n",
            "Labels formatted for metrics.\n",
            "ROUGE computed.\n",
            "BLEU computed.\n",
            "Metrics combined.\n",
            "--- Exiting compute_metrics ---\n",
            "\n",
            "CUDA cache cleared and gc.collect() called by callback before evaluation at step 4000.\n",
            "\n",
            "--- Inside compute_metrics (DEBUG) ---\n",
            "Type of eval_pred.predictions (initial): <class 'tuple'>\n",
            "Type of eval_pred.label_ids (initial): <class 'numpy.ndarray'>\n",
            "eval_pred.predictions is a tuple. Length: 2\n",
            "Taking first element of predictions tuple. New type: <class 'numpy.ndarray'>\n",
            "Predictions type (after initial processing): <class 'numpy.ndarray'>\n",
            "Labels type (after initial processing): <class 'numpy.ndarray'>\n",
            "WARNING: Predictions has unexpected 3 dimensions. Assuming logits and applying argmax.\n",
            "Predictions after argmax: New shape: (2937, 107), New dtype: int64\n",
            "Predictions shape (after processing): (2937, 107)\n",
            "Labels shape (after processing): (2937, 107)\n",
            "Labels processed (replaced -100).\n",
            "Successfully decoded 2937 predictions and 2937 labels.\n",
            "Empty strings in decoded predictions/labels replaced with 'a' for robust metric calculation.\n",
            "Labels formatted for metrics.\n",
            "ROUGE computed.\n",
            "BLEU computed.\n",
            "Metrics combined.\n",
            "--- Exiting compute_metrics ---\n",
            "\n",
            "CUDA cache cleared and gc.collect() called by callback before evaluation at step 4500.\n",
            "\n",
            "--- Inside compute_metrics (DEBUG) ---\n",
            "Type of eval_pred.predictions (initial): <class 'tuple'>\n",
            "Type of eval_pred.label_ids (initial): <class 'numpy.ndarray'>\n",
            "eval_pred.predictions is a tuple. Length: 2\n",
            "Taking first element of predictions tuple. New type: <class 'numpy.ndarray'>\n",
            "Predictions type (after initial processing): <class 'numpy.ndarray'>\n",
            "Labels type (after initial processing): <class 'numpy.ndarray'>\n",
            "WARNING: Predictions has unexpected 3 dimensions. Assuming logits and applying argmax.\n",
            "Predictions after argmax: New shape: (2937, 107), New dtype: int64\n",
            "Predictions shape (after processing): (2937, 107)\n",
            "Labels shape (after processing): (2937, 107)\n",
            "Labels processed (replaced -100).\n",
            "Successfully decoded 2937 predictions and 2937 labels.\n",
            "Empty strings in decoded predictions/labels replaced with 'a' for robust metric calculation.\n",
            "Labels formatted for metrics.\n",
            "ROUGE computed.\n",
            "BLEU computed.\n",
            "Metrics combined.\n",
            "--- Exiting compute_metrics ---\n",
            "\n",
            "CUDA cache cleared and gc.collect() called by callback before evaluation at step 5000.\n",
            "\n",
            "--- Inside compute_metrics (DEBUG) ---\n",
            "Type of eval_pred.predictions (initial): <class 'tuple'>\n",
            "Type of eval_pred.label_ids (initial): <class 'numpy.ndarray'>\n",
            "eval_pred.predictions is a tuple. Length: 2\n",
            "Taking first element of predictions tuple. New type: <class 'numpy.ndarray'>\n",
            "Predictions type (after initial processing): <class 'numpy.ndarray'>\n",
            "Labels type (after initial processing): <class 'numpy.ndarray'>\n",
            "WARNING: Predictions has unexpected 3 dimensions. Assuming logits and applying argmax.\n",
            "Predictions after argmax: New shape: (2937, 107), New dtype: int64\n",
            "Predictions shape (after processing): (2937, 107)\n",
            "Labels shape (after processing): (2937, 107)\n",
            "Labels processed (replaced -100).\n",
            "Successfully decoded 2937 predictions and 2937 labels.\n",
            "Empty strings in decoded predictions/labels replaced with 'a' for robust metric calculation.\n",
            "Labels formatted for metrics.\n",
            "ROUGE computed.\n",
            "BLEU computed.\n",
            "Metrics combined.\n",
            "--- Exiting compute_metrics ---\n",
            "\n",
            "CUDA cache cleared and gc.collect() called by callback before evaluation at step 5500.\n",
            "\n",
            "--- Inside compute_metrics (DEBUG) ---\n",
            "Type of eval_pred.predictions (initial): <class 'tuple'>\n",
            "Type of eval_pred.label_ids (initial): <class 'numpy.ndarray'>\n",
            "eval_pred.predictions is a tuple. Length: 2\n",
            "Taking first element of predictions tuple. New type: <class 'numpy.ndarray'>\n",
            "Predictions type (after initial processing): <class 'numpy.ndarray'>\n",
            "Labels type (after initial processing): <class 'numpy.ndarray'>\n",
            "WARNING: Predictions has unexpected 3 dimensions. Assuming logits and applying argmax.\n",
            "Predictions after argmax: New shape: (2937, 107), New dtype: int64\n",
            "Predictions shape (after processing): (2937, 107)\n",
            "Labels shape (after processing): (2937, 107)\n",
            "Labels processed (replaced -100).\n",
            "Successfully decoded 2937 predictions and 2937 labels.\n",
            "Empty strings in decoded predictions/labels replaced with 'a' for robust metric calculation.\n",
            "Labels formatted for metrics.\n",
            "ROUGE computed.\n",
            "BLEU computed.\n",
            "Metrics combined.\n",
            "--- Exiting compute_metrics ---\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Trimmed mT5-small + LoRA Fine-tuning on GPU with Google Drive Storage using PEFT\"\"\"\n",
        "\n",
        "# Step 0: Mount Google Drive\n",
        "# Execute this cell in Google Colab to mount your Drive\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Google Drive mounted successfully!\")\n",
        "except ImportError:\n",
        "    print(\"Running outside Google Colab. Skipping Google Drive mounting.\")\n",
        "    print(\"Ensure your base_drive_folder is correctly set for your local environment.\")\n",
        "\n",
        "import os # Import the os module\n",
        "\n",
        "# Define the base folder in Google Drive for data and outputs\n",
        "# This should be the folder containing your CSV data\n",
        "base_drive_folder = \"/content/drive/MyDrive/amharic_summarizer_lora\" # Keep this for data and general outputs\n",
        "\n",
        "# Define the directory where the trimmed model and tokenizer were saved by vocabtrimmer\n",
        "# IMPORTANT: Update this path if you saved the trimmed model to a different location\n",
        "trimmed_model_path = \"/content/drive/MyDrive/amharic_summarizer_mt5_trimmed_vocabtrimmer\"\n",
        "print(f\"Attempting to load trimmed model and tokenizer from: {trimmed_model_path}\")\n",
        "\n",
        "# Create the base output folder if it doesn't exist\n",
        "os.makedirs(base_drive_folder, exist_ok=True)\n",
        "print(f\"Training outputs (checkpoints, logs, results) will be saved to: {base_drive_folder}\")\n",
        "\n",
        "\n",
        "# Step 1: Setup and Installation\n",
        "# Install necessary libraries\n",
        "# Include peft for LoRA\n",
        "!pip install --upgrade transformers # UPGRADED: Upgrade transformers to a recent version\n",
        "!pip install --upgrade datasets\n",
        "!pip install peft accelerate evaluate rouge_score nltk pandas rawpy Pillow tensorboard\n",
        "\n",
        "# Print transformers version to verify installation\n",
        "import transformers\n",
        "print(f\"Transformers version: {transformers.__version__}\")\n",
        "\n",
        "# Note: Meteor also requires Java to be installed on your system.\n",
        "# If you still get errors for Meteor, you might need to install Java.\n",
        "# Restart your Colab runtime after installation if prompted.\n",
        "\n",
        "import json\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import gc # Import garbage collector\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq, TrainerCallback\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "from datasets import load_dataset, DatasetDict, Dataset\n",
        "\n",
        "import evaluate\n",
        "import nltk\n",
        "\n",
        "# Ensure necessary nltk data is downloaded for metrics\n",
        "nltk.download(\"punkt\", quiet=True)\n",
        "nltk.download(\"wordnet\", quiet=True)\n",
        "nltk.download('omw-1.4', quiet=True)\n",
        "nltk.download('averaged_perceptron_tagger', quiet=True) # sometimes needed for meteor, but keeping for now as it's small\n",
        "\n",
        "# Step 2: Load the Trimmed Model and Tokenizer\n",
        "# Load the model and tokenizer from the directory where vocabtrimmer saved them\n",
        "try:\n",
        "    print(f\"\\nLoading trimmed model from {trimmed_model_path}...\")\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(trimmed_model_path)\n",
        "    print(f\"Loading trimmed tokenizer from {trimmed_model_path}...\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(trimmed_model_path)\n",
        "    print(\"Trimmed model and tokenizer loaded successfully!\")\n",
        "    print(f\"Loaded model vocabulary size: {model.config.vocab_size}\")\n",
        "    print(f\"Loaded tokenizer vocabulary size: {len(tokenizer)}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading trimmed model or tokenizer from {trimmed_model_path}: {e}\")\n",
        "    print(\"Please ensure the trimmed model and tokenizer were saved correctly by vocabtrimmer\")\n",
        "    print(\"and that the 'trimmed_model_path' variable points to the correct directory.\")\n",
        "    print(\"Exiting script.\")\n",
        "    raise SystemExit(\"Failed to load trimmed model/tokenizer.\")\n",
        "\n",
        "\n",
        "# Check for CUDA availability and move model to GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print(f\"Model moved to device: {device}\")\n",
        "\n",
        "\n",
        "# Step 3: Load and Preprocess Your Data (Using three CSV files from Google Drive)\n",
        "\n",
        "# Define the paths to your CSV files within the Google Drive folder\n",
        "train_csv_path = os.path.join(base_drive_folder, 'amharic_3_train.csv')\n",
        "valid_csv_path = os.path.join(base_drive_folder, 'amharic_3_valid.csv')\n",
        "test_csv_path = os.path.join(base_drive_folder, 'amharic_3_test.csv')\n",
        "\n",
        "# IMPORTANT: Make sure you have uploaded amharic_3_train.csv, amharic_3_valid.csv,\n",
        "# and amharic_3_test.csv into the specified base_drive_folder in your Google Drive.\n",
        "\n",
        "# Load each dataset split from its respective CSV file\n",
        "try:\n",
        "    # load_dataset returns a DatasetDict, get the 'train' split for each file\n",
        "    train_dataset = load_dataset('csv', data_files=train_csv_path)['train']\n",
        "    valid_dataset = load_dataset('csv', data_files=valid_csv_path)['train']\n",
        "    test_dataset = load_dataset('csv', data_files=test_csv_path)['train']\n",
        "\n",
        "    # Select only the 'text' and 'summary' columns for each dataset\n",
        "    train_dataset = train_dataset.select_columns(['text', 'summary'])\n",
        "    valid_dataset = valid_dataset.select_columns(['text', 'summary'])\n",
        "    test_dataset = test_dataset.select_columns(['text', 'summary'])\n",
        "\n",
        "    # Combine into a DatasetDict\n",
        "    dataset = DatasetDict({\n",
        "        'train': train_dataset,\n",
        "        'validation': valid_dataset,\n",
        "        'test': test_dataset\n",
        "    })\n",
        "    print(\"\\nDataset loaded from CSV files.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"\\nError: One or more of the specified CSV files were not found in Google Drive.\")\n",
        "    print(f\"Please make sure amharic_3_train.csv, amharic_3_valid.csv, and amharic_3_test.csv\")\n",
        "    print(f\"are uploaded to your Google Drive folder: {base_drive_folder}\")\n",
        "    # Create dummy datasets for demonstration if files not found\n",
        "    print(\"Creating dummy datasets for demonstration.\")\n",
        "    dummy_train_data = {\"text\": [\"Train document one for dummy data.\", \"Train document two for dummy data.\"], \"summary\": [\"Train sum 1.\", \"Train sum 2.\"]}\n",
        "    dummy_valid_data = {\"text\": [\"Valid document one for dummy data.\"], \"summary\": [\"Valid sum 1.\"]}\n",
        "    dummy_test_data = {\"text\": [\"Test document one for dummy data.\"], \"summary\": [\"Test sum 1.\"]}\n",
        "    dataset = DatasetDict({\n",
        "        'train': Dataset.from_dict(dummy_train_data),\n",
        "        'validation': Dataset.from_dict(dummy_valid_data),\n",
        "        'test': Dataset.from_dict(dummy_test_data)\n",
        "    })\n",
        "\n",
        "\n",
        "print(\"Dataset sizes:\")\n",
        "print(f\"Train size: {len(dataset['train'])}\")\n",
        "print(f\"Validation size: {len(dataset['validation'])}\")\n",
        "print(f\"Test size: {len(dataset['test'])}\")\n",
        "\n",
        "# Define the preprocessing function (DataCollator will handle padding)\n",
        "# Use the loaded (trimmed) tokenizer\n",
        "def preprocess_function(examples):\n",
        "    # Tokenize documents (text column)\n",
        "    # Adjust max_length based on the typical length of your documents\n",
        "    model_inputs = tokenizer(\n",
        "        examples['text'],\n",
        "        max_length=512, # Max length for inputs\n",
        "        truncation=True,\n",
        "        # padding is handled by DataCollatorForSeq2Seq\n",
        "    )\n",
        "\n",
        "    # Tokenize summaries (summary column)\n",
        "    # Adjust max_length based on the typical length of your summaries\n",
        "    labels = tokenizer(\n",
        "        examples['summary'],\n",
        "        max_length=128, # Max length for labels\n",
        "        truncation=True,\n",
        "        # padding is handled by DataCollatorForSeq2Seq\n",
        "    )\n",
        "\n",
        "    # Assign input_ids of summaries as labels\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "\n",
        "    return model_inputs\n",
        "\n",
        "# Apply the preprocessing function to all splits\n",
        "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# Set the format of the datasets to PyTorch tensors\n",
        "# Specify which columns should be converted to tensors\n",
        "tokenized_dataset.set_format(\"torch\", columns=['input_ids', 'attention_mask', 'labels'])\n",
        "\n",
        "# Now, the variables for each split are directly available\n",
        "tokenized_train_dataset = tokenized_dataset['train']\n",
        "tokenized_eval_dataset = tokenized_dataset['validation']\n",
        "tokenized_test_dataset = tokenized_dataset['test']\n",
        "\n",
        "# Step 4: Configure and Apply LoRA\n",
        "# Define LoRA configuration\n",
        "# Apply LoRA on the TRIMMED model\n",
        "lora_config = LoraConfig(\n",
        "    r=8, # LoRA attention dimension - Adjust based on experimentation\n",
        "    lora_alpha=16, # Alpha parameter for LoRA scaling - Adjust based on experimentation\n",
        "    target_modules=[\"q\", \"v\"], # Common target modules for attention in T5 variants\n",
        "    lora_dropout=0.1, # Dropout probability for LoRA layers - Adjust based on experimentation\n",
        "    bias=\"none\", # Bias type: 'none', 'all', or 'lora_only'\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM # Task type for sequence-to-sequence models\n",
        ")\n",
        "\n",
        "# Apply LoRA to the trimmed base model\n",
        "# Ensure the model is on the correct device before applying PEFT if needed,\n",
        "# but get_peft_model usually handles device placement.\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "# Print trainable parameters (will be on GPU)\n",
        "print(\"\\nTrainable parameters (LoRA on Trimmed Model):\")\n",
        "model.print_trainable_parameters()\n",
        "\n",
        "# --- Custom Callback for Cache Clearing ---\n",
        "class ClearCacheCallback(TrainerCallback):\n",
        "    \"\"\"\n",
        "    A TrainerCallback that clears the CUDA cache before evaluation steps.\n",
        "    Using on_step_end hook to check if evaluation is about to happen.\n",
        "    Includes gc.collect().\n",
        "    \"\"\"\n",
        "    def on_step_end(self, args, state, control, **kwargs):\n",
        "        # Check if evaluation is scheduled for the next step\n",
        "        # This condition is true when state.global_step is a multiple of args.eval_steps\n",
        "        # and state.global_step > 0\n",
        "        if args.eval_strategy == \"steps\" and state.global_step > 0 and args.eval_steps and state.global_step % args.eval_steps == 0:\n",
        "             if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "                # Also try garbage collection\n",
        "                gc.collect()\n",
        "                print(f\"\\nCUDA cache cleared and gc.collect() called by callback before evaluation at step {state.global_step}.\")\n",
        "                # Set control.should_evaluate to True to ensure evaluation happens right after this step end\n",
        "                # This might already be handled by the Trainer, but explicit can help sometimes.\n",
        "                control.should_evaluate = True\n",
        "\n",
        "\n",
        "# Step 5: Define Training Arguments and Trainer (Configured for GPU with Drive Outputs)\n",
        "\n",
        "# Define the output directory within your Google Drive for training logs and checkpoints\n",
        "# Using the base_drive_folder for training outputs\n",
        "training_output_dir = os.path.join(base_drive_folder, \"trimmed_lora_checkpoints\")\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(training_output_dir, exist_ok=True)\n",
        "print(f\"Training outputs (checkpoints, logs) will be saved to: {training_output_dir}\")\n",
        "\n",
        "\n",
        "# Instantiate Data Collator (Handles padding batches dynamically)\n",
        "# We pass the tokenizer so it knows the pad token ID\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model) # Pass model (PEFT model on trimmed base) here\n",
        "\n",
        "# Define training arguments (Revised for GPU with Drive Checkpointing and TensorBoard)\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=training_output_dir, # Output directory for checkpoints and logs (in Drive)\n",
        "    num_train_epochs=3, # Number of training epochs - Adjust based on convergence\n",
        "    per_device_train_batch_size=2, # Batch size per device during training\n",
        "    per_device_eval_batch_size=1, # Evaluation batch size\n",
        "    gradient_accumulation_steps=2, # Gradient accumulation steps to compensate for smaller batch size\n",
        "    learning_rate=1e-5, # CRITICAL FIX: Reduced Learning rate significantly to prevent NaNs\n",
        "    weight_decay=0.01, # Weight decay - Adjust based on experimentation\n",
        "    eval_strategy=\"steps\", # Evaluate every N steps to match save_strategy\n",
        "    eval_steps=500, # Evaluate every 500 training steps (matches save_steps)\n",
        "    save_strategy=\"steps\", # Save checkpoint every N steps\n",
        "    save_steps=500, # Save a checkpoint every 500 training steps\n",
        "    save_total_limit=3, # Optional: Limit the total number of checkpoints to save\n",
        "    load_best_model_at_end=True, # Load the best model at the end of training based on metric_for_best_model\n",
        "    metric_for_best_model=\"rougeL\", # Metric to monitor for best model - Change if needed\n",
        "    greater_is_better=True, # Set to False for metrics like loss\n",
        "    report_to=\"tensorboard\", # Log metrics to TensorBoard\n",
        "    push_to_hub=False, # Set to True if you want to push to Hugging Face Hub\n",
        "    label_names=[\"labels\"], # Explicitly tell the Trainer your label column name\n",
        "    fp16=False, # CRITICAL FIX: Disable mixed precision training to prevent NaNs\n",
        "    # bf16=torch.cuda.is_available() and torch.cuda.is_bf16_supported(), # Use bf16 if GPU supports it\n",
        ")\n",
        "\n",
        "# Define compute_metrics function for evaluation\n",
        "metric_rouge = evaluate.load(\"rouge\")\n",
        "metric_bleu = evaluate.load(\"bleu\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions = eval_pred.predictions\n",
        "    labels = eval_pred.label_ids\n",
        "\n",
        "    # Debugging prints to inspect types and shapes\n",
        "    print(\"\\n--- Inside compute_metrics (DEBUG) ---\")\n",
        "    print(f\"Type of eval_pred.predictions (initial): {type(eval_pred.predictions)}\")\n",
        "    print(f\"Type of eval_pred.label_ids (initial): {type(eval_pred.label_ids)}\")\n",
        "\n",
        "    # CRITICAL FIX: If predictions is a tuple (e.g., logits and hidden states), take the first element (logits)\n",
        "    if isinstance(predictions, tuple):\n",
        "        print(f\"eval_pred.predictions is a tuple. Length: {len(predictions)}\")\n",
        "        predictions = predictions[0] # Assume the first element is the actual generated sequences (logits)\n",
        "        print(f\"Taking first element of predictions tuple. New type: {type(predictions)}\")\n",
        "\n",
        "    # Ensure predictions and labels are NumPy arrays\n",
        "    if isinstance(predictions, torch.Tensor):\n",
        "        predictions = predictions.cpu().numpy()\n",
        "    if isinstance(labels, torch.Tensor):\n",
        "        labels = labels.cpu().numpy()\n",
        "\n",
        "    print(f\"Predictions type (after initial processing): {type(predictions)}\")\n",
        "    print(f\"Labels type (after initial processing): {type(labels)}\")\n",
        "\n",
        "    # CRITICAL FIX: If predictions are logits (3D array), convert to token IDs using argmax\n",
        "    if predictions.ndim == 3:\n",
        "        print(f\"WARNING: Predictions has unexpected 3 dimensions. Assuming logits and applying argmax.\")\n",
        "        predictions = np.argmax(predictions, axis=-1) # Convert logits to token IDs\n",
        "        print(f\"Predictions after argmax: New shape: {predictions.shape}, New dtype: {predictions.dtype}\")\n",
        "\n",
        "    # Further check for dimensions: if predictions is 3D (e.g., batch_size, seq_len, 1), squeeze it\n",
        "    # This handles cases where the model output might have an extra dimension of size 1\n",
        "    if predictions.ndim == 3 and predictions.shape[-1] == 1:\n",
        "        predictions = predictions.squeeze(-1)\n",
        "        print(f\"Predictions was 3D with last dim 1, squeezed to 2D. New shape: {predictions.shape}\")\n",
        "    elif predictions.ndim > 2:\n",
        "        # If it's more than 2D and not just a trailing 1, this is unexpected for token IDs\n",
        "        print(f\"WARNING: Predictions has unexpected {predictions.ndim} dimensions (after argmax check). Expected 2D.\")\n",
        "        predictions = predictions.reshape(predictions.shape[0], -1) # Attempt to flatten if possible\n",
        "        print(f\"Attempted to reshape predictions to 2D. New shape: {predictions.shape}\")\n",
        "\n",
        "    # Ensure predictions are integers (important for tokenizer.batch_decode)\n",
        "    if predictions.dtype != np.int64 and predictions.dtype != np.int32:\n",
        "        print(f\"WARNING: Predictions dtype is {predictions.dtype}, converting to int64.\")\n",
        "        predictions = predictions.astype(np.int64)\n",
        "    if labels.dtype != np.int64 and labels.dtype != np.int32:\n",
        "        print(f\"WARNING: Labels dtype is {labels.dtype}, converting to int64.\")\n",
        "        labels = labels.astype(np.int64)\n",
        "\n",
        "    print(f\"Predictions shape (after processing): {predictions.shape}\")\n",
        "    print(f\"Labels shape (after processing): {labels.shape}\")\n",
        "\n",
        "    # Replace -100 in labels as they are ignored in loss calculation\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    print(\"Labels processed (replaced -100).\")\n",
        "\n",
        "    try:\n",
        "        # Decode predictions and labels, removing special tokens\n",
        "        decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "        print(f\"Successfully decoded {len(decoded_preds)} predictions and {len(decoded_labels)} labels.\")\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: Failed to decode predictions/labels in compute_metrics: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        raise # Re-raise to crash session with specific error\n",
        "\n",
        "    # FIX: Replace empty strings with a single character 'a' to prevent ZeroDivisionError in BLEU\n",
        "    # This is crucial for metrics like BLEU that perform length calculations.\n",
        "    decoded_preds_for_metrics = [pred if pred else \"a\" for pred in decoded_preds]\n",
        "    decoded_labels_for_metrics = [label if label else \"a\" for label in decoded_labels]\n",
        "    print(\"Empty strings in decoded predictions/labels replaced with 'a' for robust metric calculation.\")\n",
        "\n",
        "    # Some metrics expect a list of lists for references\n",
        "    formated_decoded_labels_for_some_metrics = [[label] for label in decoded_labels_for_metrics] # Use the cleaned lists for metrics\n",
        "    print(\"Labels formatted for metrics.\")\n",
        "\n",
        "    # --- Compute Metrics ---\n",
        "    try:\n",
        "        # Rouge\n",
        "        rouge_results = metric_rouge.compute(predictions=decoded_preds_for_metrics, references=decoded_labels_for_metrics)\n",
        "        print(\"ROUGE computed.\")\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: Failed to compute ROUGE in compute_metrics: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        raise # Re-raise\n",
        "\n",
        "    try:\n",
        "        # BLEU (requires references as list of lists)\n",
        "        bleu_results = metric_bleu.compute(predictions=decoded_preds_for_metrics, references=formated_decoded_labels_for_some_metrics)\n",
        "        print(\"BLEU computed.\")\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: Failed to compute BLEU in compute_metrics: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        raise # Re-raise\n",
        "\n",
        "    # Combine metrics - only include ROUGE and BLEU\n",
        "    combined_results = {\n",
        "        \"rouge1\": rouge_results[\"rouge1\"], # F1 score is commonly reported\n",
        "        \"rouge2\": rouge_results[\"rouge2\"],\n",
        "        \"rougeL\": rouge_results[\"rougeL\"],\n",
        "        \"bleu\": bleu_results[\"bleu\"],\n",
        "    }\n",
        "    print(\"Metrics combined.\")\n",
        "    print(\"--- Exiting compute_metrics ---\")\n",
        "    # The Trainer expects a dictionary of metrics\n",
        "    return combined_results\n",
        "\n",
        "\n",
        "# Create Trainer instance, adding the custom callback\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model, # This is the PEFT model on the TRIMMED base model\n",
        "    args=training_args, # These are the GPU-configured args with Drive checkpointing and reporting\n",
        "    train_dataset=tokenized_train_dataset,\n",
        "    eval_dataset=tokenized_eval_dataset,\n",
        "    tokenizer=tokenizer, # Pass the trimmed tokenizer here\n",
        "    data_collator=data_collator, # Add the data collator here\n",
        "    compute_metrics=compute_metrics, # Pass the compute_metrics function\n",
        "    callbacks=[ClearCacheCallback()], # Add the custom cache clearing callback here\n",
        ")\n",
        "\n",
        "\n",
        "# Step 6: Train the Model & Measure Time (Includes Resuming from Checkpoint in Drive)\n",
        "print(\"\\nStarting training (LoRA on Trimmed Model)...\")\n",
        "\n",
        "# --- Resume Training Logic ---\n",
        "# Check if there's a checkpoint to resume from in the output directory\n",
        "# The Trainer saves checkpoints in subdirectories like 'checkpoint-XXXX'\n",
        "latest_checkpoint_dir = None\n",
        "if os.path.isdir(training_args.output_dir):\n",
        "    # Find all checkpoint directories\n",
        "    checkpoints = [m for m in os.listdir(training_args.output_dir) if m.startswith('checkpoint-')]\n",
        "    if checkpoints:\n",
        "        # Sort checkpoints by step number to find the latest\n",
        "        latest_checkpoint_dir = os.path.join(training_args.output_dir, sorted(checkpoints, key=lambda x: int(x.split('-')[-1]))[-1])\n",
        "        print(f\"Found latest checkpoint: {latest_checkpoint_dir}\")\n",
        "\n",
        "# Set resume_from_checkpoint to the latest found checkpoint if it exists\n",
        "resume_from_checkpoint = latest_checkpoint_dir if latest_checkpoint_dir and os.path.isdir(latest_checkpoint_dir) else None\n",
        "\n",
        "if resume_from_checkpoint:\n",
        "     print(f\"Resuming training from checkpoint: {resume_from_checkpoint}\")\n",
        "else:\n",
        "     print(\"No checkpoint found, starting fresh training.\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Start training (pass resume_from_checkpoint if a checkpoint was found)\n",
        "train_output = trainer.train(resume_from_checkpoint=resume_from_checkpoint)\n",
        "\n",
        "end_time = time.time()\n",
        "total_training_time_seconds = end_time - start_time\n",
        "total_training_time_minutes = total_training_time_seconds / 60.0\n",
        "\n",
        "print(f\"\\nTotal training time (LoRA on Trimmed Model): {total_training_time_seconds:.2f} seconds ({total_training_time_minutes:.2f} minutes)\")\n",
        "\n",
        "\n",
        "# Step 7: Evaluate the Model on the Test Set and Get Metrics\n",
        "print(\"\\n--- Starting Model Evaluation on Test Set ---\")\n",
        "try:\n",
        "    # --- Explicitly Clear CUDA Cache Before Final Evaluation ---\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect() # Also call gc.collect() here\n",
        "        print(\"\\nCUDA cache cleared and gc.collect() called explicitly before final evaluation.\")\n",
        "    else:\n",
        "        print(\"\\nCUDA not available, skipping cache clear before final evaluation.\")\n",
        "\n",
        "    print(\"Calling trainer.evaluate...\")\n",
        "    evaluation_results = trainer.evaluate(eval_dataset=tokenized_test_dataset)\n",
        "    print(\"trainer.evaluate completed.\")\n",
        "\n",
        "    print(\"\\nEvaluation Metrics (LoRA on Trimmed Model):\")\n",
        "    print(evaluation_results)\n",
        "\n",
        "    # --- Save Evaluation Results to File ---\n",
        "    eval_results_file = os.path.join(base_drive_folder, \"trimmed_lora_evaluation_results.json\")\n",
        "    with open(eval_results_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(evaluation_results, f, indent=4)\n",
        "    print(f\"\\nEvaluation results saved to: {eval_results_file}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nERROR during Step 7 (Model Evaluation): {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc() # Print full traceback for detailed error\n",
        "\n",
        "\n",
        "# Step 8: Plot Training vs Validation Loss for Convergence Analysis\n",
        "print(\"\\n--- Starting Loss Curve Plotting ---\")\n",
        "try:\n",
        "    # Extract loss and eval_loss from the trainer's log history\n",
        "    train_loss_entries = [entry for entry in trainer.state.log_history if 'loss' in entry]\n",
        "    eval_loss_entries = [entry for entry in trainer.state.log_history if 'eval_loss' in entry]\n",
        "\n",
        "    train_steps = [entry['step'] for entry in train_loss_entries]\n",
        "    train_losses = [entry['loss'] for entry in train_loss_entries]\n",
        "\n",
        "    # For evaluation, the step corresponds to the global step at which evaluation was performed\n",
        "    eval_steps = [entry['step'] for entry in eval_loss_entries]\n",
        "    eval_losses = [entry['eval_loss'] for entry in eval_loss_entries]\n",
        "\n",
        "    if train_steps and eval_steps:\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(train_steps, train_losses, label=\"Training Loss\", marker='o', linestyle='-')\n",
        "        plt.plot(eval_steps, eval_losses, label=\"Validation Loss\", marker='s', linestyle='--')\n",
        "        plt.xlabel(\"Training Steps\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.title(\"Training vs Validation Loss Over Steps\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        # Save the plot to Google Drive\n",
        "        loss_plot_path = os.path.join(base_drive_folder, \"trimmed_lora_loss_curve.png\")\n",
        "        plt.savefig(loss_plot_path)\n",
        "        print(f\"Loss curve plot saved to: {loss_plot_path}\")\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"Not enough data in log history to plot loss curves. Ensure eval_strategy and logging_steps are configured.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nERROR during Step 8 (Loss Plotting): {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "\n",
        "# Step 9: Save the Final (Best) LoRA Weights to Drive (Parameter-Efficient Saving)\n",
        "print(\"\\n--- Starting Model Saving ---\")\n",
        "try:\n",
        "    # After trainer.train() finishes (and because load_best_model_at_end=True),\n",
        "    # the model object in memory is the best model found during training.\n",
        "    # Save only the LoRA weights, not the full trimmed base model\n",
        "    lora_output_dir = os.path.join(base_drive_folder, \"trimmed_lora_final_best_lora\")\n",
        "    # Note: We save the PEFT model, which includes the LoRA weights and references the base model\n",
        "    model.save_pretrained(lora_output_dir) # Save PEFT model weights\n",
        "    print(f\"\\nFinal (best) LoRA weights saved to {lora_output_dir}\")\n",
        "\n",
        "    # To save the tokenizer along with the LoRA weights (recommended):\n",
        "    tokenizer.save_pretrained(lora_output_dir)\n",
        "    print(f\"Tokenizer saved to {lora_output_dir}\")\n",
        "\n",
        "    # --- How to Load the Saved Trimmed Model with LoRA Weights Later ---\n",
        "    print(f\"To load the trimmed base model and apply the saved LoRA weights later, you would do:\")\n",
        "    print(f\"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\")\n",
        "    print(f\"from peft import PeftModel\")\n",
        "    print(f\"\")\n",
        "    print(f\"# Path to the directory where you saved the trimmed base model (from vocabtrimmer)\")\n",
        "    print(f\"trimmed_base_model_path = '{trimmed_model_path}'\")\n",
        "    print(f\"# Path to the directory where you saved the fine-tuned LoRA weights\")\n",
        "    print(f\"saved_lora_dir = '{lora_output_dir}'\")\n",
        "    print(f\"\")\n",
        "    print(f\"# Load the trimmed base model\")\n",
        "    print(f\"loaded_trimmed_model = AutoModelForSeq2SeqLM.from_pretrained(trimmed_base_model_path)\")\n",
        "    print(f\"\")\n",
        "    print(f\"# Load the LoRA weights and apply them to the trimmed base model\")\n",
        "    print(f\"loaded_peft_model = PeftModel.from_pretrained(loaded_trimmed_model, saved_lora_dir)\")\n",
        "    print(f\"\")\n",
        "    print(f\"# Load the trimmed tokenizer\")\n",
        "    print(f\"loaded_tokenizer = AutoTokenizer.from_pretrained(saved_lora_dir)\") # Tokenizer was saved with LoRA weights\n",
        "    print(f\"\")\n",
        "    print(f\"# If running on GPU, ensure model is on GPU\")\n",
        "    print(f\"# import torch\")\n",
        "    print(f\"# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\")\n",
        "    print(f\"# loaded_peft_model.to(device)\")\n",
        "    print(f\"\")\n",
        "    print(f\"# Set to evaluation mode\")\n",
        "    print(f\"# loaded_peft_model.eval()\")\n",
        "    print(f\"\")\n",
        "    print(f\"print(f'Successfully loaded trimmed model and applied LoRA weights from {saved_lora_dir}')\")\n",
        "    print(f\"print(f'Loaded model vocabulary size: {loaded_peft_model.config.vocab_size}')\")\n",
        "    print(f\"print(f'Loaded tokenizer vocabulary size: {len(loaded_tokenizer)}')\")\n",
        "    print(f\"\")\n",
        "    print(f\"# Example Inference (Optional)\")\n",
        "    print(f\"# text_to_summarize = 'የአማርኛ ጽሑፍ እዚህ ይገባል...'\")\n",
        "    print(f\"# inputs = loaded_tokenizer(text_to_summarize, return_tensors='pt', max_length=512, truncation=True).to(device)\")\n",
        "    print(f\"# output_tokens = loaded_peft_model.generate(**inputs, max_new_tokens=128, num_beams=4, early_stopping=True)\")\n",
        "    print(f\"# generated_summary = loaded_tokenizer.decode(output_tokens[0], skip_special_tokens=True)\")\n",
        "    print(f\"# print(f'Generated Summary: {generated_summary}')\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nERROR during Step 9 (Model Saving): {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "\n",
        "# Step 10: Display Example Summaries with ROUGE Scores\n",
        "print(\"\\n--- Starting Example Summaries Generation ---\")\n",
        "try:\n",
        "    # Get predictions for the test set\n",
        "    # Setting max_new_tokens is important for generation\n",
        "    # Setting num_beams for beam search (optional but common)\n",
        "    generated_predictions = trainer.predict(\n",
        "        test_dataset=tokenized_test_dataset,\n",
        "        max_new_tokens=128, # Max length of generated summary (matches labels)\n",
        "        num_beams=4, # Number of beams for beam search\n",
        "        # early_stopping=True,\n",
        "    )\n",
        "    print(\"trainer.predict for example summaries completed.\")\n",
        "\n",
        "    # Extract predictions (token IDs) and labels (token IDs)\n",
        "    preds = generated_predictions.predictions\n",
        "    labels = generated_predictions.label_ids\n",
        "\n",
        "    # Replace -100 in labels as they are ignored in loss calculation\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "\n",
        "    # Decode predictions and labels back to text\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    print(f\"Successfully decoded {len(decoded_preds)} predictions and {len(decoded_labels)} labels.\")\n",
        "\n",
        "    # FIX: Replace empty strings with a single character 'a' to prevent ZeroDivisionError in BLEU\n",
        "    # This is crucial for metrics like BLEU that perform length calculations.\n",
        "    decoded_preds_for_metrics = [pred if pred else \"a\" for pred in decoded_preds]\n",
        "    decoded_labels_for_metrics = [label if label else \"a\" for label in decoded_labels]\n",
        "    print(\"Empty strings in decoded predictions/labels replaced with 'a' for robust metric calculation.\")\n",
        "\n",
        "\n",
        "    # Some metrics expect a list of lists for references\n",
        "    formated_decoded_labels_for_some_metrics = [[label] for label in decoded_labels_for_metrics] # Use the cleaned lists for metrics\n",
        "    print(\"Labels formatted for metrics.\")\n",
        "\n",
        "    # --- Compute Metrics ---\n",
        "    # Re-compute ROUGE and BLEU for the example summaries, as these are based on the generated_predictions from trainer.predict\n",
        "    # and not the eval_pred from compute_metrics during training.\n",
        "    try:\n",
        "        rouge_results_examples = metric_rouge.compute(predictions=decoded_preds_for_metrics, references=decoded_labels_for_metrics)\n",
        "        print(\"ROUGE computed for example summaries.\")\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: Failed to compute ROUGE for example summaries: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        rouge_results_examples = {\"rouge1\": 0.0, \"rouge2\": 0.0, \"rougeL\": 0.0} # Fallback\n",
        "\n",
        "    print(\"\\nExample Summaries with ROUGE Scores:\")\n",
        "    num_examples_to_display = 5 # Display a few examples\n",
        "    for i in range(min(num_examples_to_display, len(tokenized_test_dataset))):\n",
        "        original_text = dataset['test'][i]['text']\n",
        "        reference_summary = decoded_labels[i]\n",
        "        generated_summary = decoded_preds[i]\n",
        "\n",
        "        # Compute ROUGE for individual example (optional, but good for inspection)\n",
        "        # Note: For single examples, ensure inputs are lists of strings\n",
        "        single_rouge = metric_rouge.compute(predictions=[generated_summary if generated_summary else \"a\"],\n",
        "                                            references=[reference_summary if reference_summary else \"a\"])\n",
        "\n",
        "        print(f\"\\n--- Example {i+1} ---\")\n",
        "        print(f\"Original Text: {original_text[:500]}...\") # Truncate long texts for display\n",
        "        print(f\"Reference Summary: {reference_summary}\")\n",
        "        print(f\"Generated Summary: {generated_summary}\")\n",
        "        print(f\"  ROUGE-1 F1: {single_rouge['rouge1']:.4f}\")\n",
        "        print(f\"  ROUGE-2 F1: {single_rouge['rouge2']:.4f}\")\n",
        "        print(f\"  ROUGE-L F1: {single_rouge['rougeL']:.4f}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nERROR during Step 10 (Example Summaries Generation): {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "print(\"\\nScript finished.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h85jXdBsSz2a"
      },
      "execution_count": 2,
      "outputs": []
    }
  ]
}